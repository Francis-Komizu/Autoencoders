# Autoencoders Based Voice Conversion

## Introduction

This repository contains my code and results for the course *Scientific Research Training*. 

Voice conversion is a technique that transforms one speaker's voice to that of another, while preserving the linguistic and prosodic content. In recent years, many deep-learning based models, such as GAN, have achieved impressive results in this field. 

As a starting point, I choose autoencoder, a generative model, which is free from parallel training data. In the long run, I will step into other variants, including variational autoencoder and conditional variational autoencoder.



## References

https://github.com/auspicious3000/autovc

[jaywalnut310/vits: VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech ](https://github.com/jaywalnut310/vits)

[yl4579/StarGANv2-VC: StarGANv2-VC: A Diverse, Unsupervised, Non-parallel Framework for Natural-Sounding Voice Conversion](https://github.com/yl4579/StarGANv2-VC)
